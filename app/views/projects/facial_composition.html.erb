
<script>
    $( document ).ready(function() {
        var viewer = OpenSeadragon({
            id: "openseadragon-viewer",
            prefixUrl: "/assets/openseadragon-icon/",
            tileSources: "/assets/book_recommendation_skipgram.dzi",
            showNavigator: true
        });
        viewer.addHandler('open', function () {
            if (gon.zoom_center !== -1) {
                imagex=gon.zoom_center[0];
                imagey=gon.zoom_center[1];
                viewer.viewport.fitBounds(viewer.viewport.imageToViewportRectangle(imagex-225,imagey-300,600,800), true);
            }
        });

        $("input[id='books-search-txt']").autocomplete({
            source: '/projects/visual_recommender_book_search'
        });
    })
</script>
<div class="wrapper">
  <div class="profile">

    <section class="profile-content" id="content">
      <div class="profile-description">
        <p>Facial Composition with Variational Autoencoder and Bayesian Optimization</p>
      </div>
      <div class="menu-category">
        <h3 class="menu-category-name">Introduction</h3>
        <article class="article-text">
          <%= link_to "Variational Autoencoder", "https://arxiv.org/abs/1606.05908" %> is a type of generative neural network model.
          It makes strong assumptions for the distribution of latent variables, which allows it to map the original representations onto a continuous
          latent space. We could move along the space and any point on this latent space is able to be reconstructed into a similar form with the original representation. <br>
          <br>
          With <%= link_to "Bayesian Optimization", "https://www.mathworks.com/help/stats/bayesian-optimization-algorithm.html"%> we could heuristically solve optimization problem
          with a few sampling points and without an explicit expression for objective function. <br>
          Utilizing this, we could build an intelligent user interface, which is able to locate
          the desired result from a large search space by asking the user a few simple comparisons. <br>
          <br>
          This project applies VAE and Bayesian Optimization to the composition of facial images. With the right image databases to train from, it could have wide applications from
          photo editing to suspect facial construction. <br>
          <br>
          VAE is great for learning latent spaces that are well structured, where specific directions encode a meaningful axis of variation in the data. <br>
          With facial data, we could potentially identify independent vectors in latent space that allows us to manipulate the image such as turn a male to a female face,
          turn a sad face into a smile face.<br>
          That also means, with Bayesian Optimization, we could search the latent space to freely adjust for the features we want in a face.<br>
        </article>
      </div>
      <div class="menu-category">
        <h3 class="menu-category-name">Data</h3>
        <article class="article-text">
          Static html wikipedia page dumps are downloaded directly from <%= link_to "wikimedia downloads page","https://dumps.wikimedia.org/"%>.<br>
          Wikistats pageview files are downloaded from <%= link_to "wikimedia","https://dumps.wikimedia.org/other/pagecounts-ez/"%><br>
          Pageview stats allow us to gain information regarding the importance of categories or entries. <br>
          These dumps are then parsed and imported into Postgres database using Douwe Osinga's <%= link_to "Wiki_import code","https://github.com/DOsinga/wiki_import"%>.<br>
          <br>

        </article>
      </div>
      <div class="menu-category">
        <h3 class="menu-category-name">Model</h3>
        <article>
          This project investigates two models for calculating the relative relationships among wiki book pages.
          <ol>
            <br>
            <li>
              1. Co-occurrence matrix<br>
              A single co-occurrence matrix is generated which count the number of links that are shared between two books.<br>
              The <%= link_to "jaccard distance", 'https://en.wikipedia.org/wiki/Jaccard_index'%> is used to calculate nearest neighbors of each book. <br>
              This method is simple, but it suffers from high dimensionality as the dimension of the matrix equals the number of books in question. <br>
              Adding new books to the matrix is convenient and fast, but querying for each book requires heavy calculation on the entire matrix. <br>
              For the purpose of 2d visualization of the books, reducing the dimensions to 2d causes too much loss of information.<br>
            </li>
            <br>
            <li>
              2. Neural Network's Embedding Model<br>
              Neural network's embedding layer (mostly used in NLP) could project high dimensional vectors onto lower dimension by training the neural network for a particular task.<br>
              By defining a simple task: predicting whether or not two books share the same reference, We could obtain a reduced vector for each book. <br>
              This will allow easy storage and fast retrieval of recommentation results.<br>
              The result obtained from this method is used to create the demo below. <br>
            </li>
          </ol>
        </article>
      </div>
      <div class="menu-category">
        <h3 class="menu-category-name">Implementation</h3>
        <%= link_to "source code" , "https://github.com/luliu31415926/visual_book_recommender"%>
        <article>
          Due to limitation of computing resources, only 226600 html wikipages are imported. <br>
          Top 500 most popular books are used in the calculation and training.<br>
          Data was stored in postgreSQL database.<br>
          The Neural Network with Embedding Layer was trained using KERAS in Python Jupyter notebook.<br>
          Demo is hosted online with <%= link_to "openseadragon", "https://openseadragon.github.io/"%>.<br>
          After reducing the dimension to 20 with embedding, I mapped the embedding vectors to 2d using TSNE model for visualization<br>
        </article>
      </div>
      <div class="menu-category">
        <h3 class="menu-category-name">Demo</h3>
        <div class="demo-left">
          <%= form_tag "/projects/visual_recommender", method: "get" , class:"demo-form" do %>
              <label for="books-search-txt">Pick a book: </label>
              <%= text_field_tag 'books-search-txt' %>
              <%= submit_tag 'Go!', class:"btn btn-success"%>
          <% end %>
          <div >
            <% if @book %>
                <table>
                  <caption>10 Most Similar Books:</caption>
                  <% @neighbors.each do |n| %>
                      <tr><td><%= n.title %></td></tr>
                  <% end %>
                </table>
            <% end %>
          </div>
        </div>
        <div class="demo-right">
          <div id="openseadragon-viewer" style="width: 600px; height: 800px;"></div>
        </div>
      </div>
    </section>
  </div>
</div>

